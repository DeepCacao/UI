# ParÃ¡metros del Modelo ONNX para DetecciÃ³n de Enfermedades en Cacao

## ğŸ“Š InformaciÃ³n Detectada del Modelo Actual

### Estructura del Modelo
- **Formato**: ONNX (exportado desde YOLOv11 OBB)
- **Dimensiones de salida**: `[1, 8, 21504]`
  - `1` = batch size
  - `8` = features (4 coords + 3 clases + 1 Ã¡ngulo OBB)
  - `21504` = anchors/detecciones posibles
- **TamaÃ±o de entrada**: `1024x1024 pÃ­xeles`
- **Clases**: 3 (Fitoftora, Monilia, Sana)

### Estructura de Features (8 dimensiones)
```
[0] = cx (centro x)
[1] = cy (centro y)
[2] = w  (ancho)
[3] = h  (alto)
[4] = score_Fitoftora   (logit, requiere sigmoid)
[5] = score_Monilia     (logit, requiere sigmoid)
[6] = score_Sana        (logit, requiere sigmoid)
[7] = angle             (Ã¡ngulo para OBB, no usado actualmente)
```

## âš™ï¸ ParÃ¡metros de Inferencia Actuales

### Pre-procesamiento
- **Redimensionamiento**: 1024x1024 (mantener aspect ratio o stretch?)
- **NormalizaciÃ³n**: Dividir por 255.0 (rango [0, 1])
- **Formato de color**: RGB
- **Orden de canales**: NCHW (Batch, Channels, Height, Width)

### Post-procesamiento
- **ActivaciÃ³n de scores**: Sigmoid (los scores vienen en formato logit)
- **Umbral de confianza**: `0.5` (actualmente, ajustable)
- **NMS IoU Threshold**: `0.1` (super agresivo, ajustable)

## ğŸš¨ PROBLEMAS ACTUALES

### Problema Principal: Demasiadas Detecciones Duplicadas
**SÃ­ntoma**: Miles de cajas solapadas en una sola mazorca

**Posibles causas**:
1. â“ **Formato de coordenadas incorrecto**
   - Â¿Las coordenadas son absolutas (0-1024) o normalizadas (0-1)?
   - Â¿Las coordenadas necesitan ser multiplicadas por el tamaÃ±o de la imagen?

2. â“ **Anchors no procesados correctamente**
   - YOLO normalmente usa anchors predefinidos que se suman a las predicciones
   - Â¿El modelo exportado a ONNX ya incluye los anchors en las coordenadas?

3. â“ **Formato OBB vs Standard**
   - Â¿Las coordenadas son para cajas orientadas (con Ã¡ngulo)?
   - Â¿O son cajas estÃ¡ndar (axis-aligned)?

## ğŸ“‹ INFORMACIÃ“N NECESARIA DE TU AMIGO

Por favor pregÃºntale:

### 1. ParÃ¡metros de Entrenamiento
```python
# Â¿CuÃ¡les fueron estos parÃ¡metros al entrenar?
conf_threshold = ?        # Umbral de confianza usado
iou_threshold = ?         # Umbral de IoU para NMS
imgsz = ?                # TamaÃ±o de imagen (1024 confirmado)
```

### 2. Formato de ExportaciÃ³n ONNX
```python
# Â¿CÃ³mo se exportÃ³ el modelo?
# Ejemplo:
model.export(
    format='onnx',
    imgsz=1024,
    simplify=True,  # Â¿EstÃ¡ simplificado?
    dynamic=False,
    # ... otros parÃ¡metros
)
```

### 3. Script de ValidaciÃ³n en Python
Si puede compartir el cÃ³digo que usÃ³ para **validar** el modelo .onnx despuÃ©s de exportarlo, serÃ­a ideal. Algo como:

```python
import onnxruntime as ort
import cv2
import numpy as np

session = ort.InferenceSession("best.onnx")

# Â¿CÃ³mo preprocesa la imagen?
img = cv2.imread("test.jpg")
# ... preprocesamiento

# Â¿CÃ³mo ejecuta la inferencia?
outputs = session.run(None, {session.get_inputs()[0].name: img})

# Â¿CÃ³mo parsea las salidas?
# ... cÃ³digo de postprocesamiento
```

### 4. MÃ©tricas de Rendimiento Esperadas
- Â¿CuÃ¡l es el **mAP** del modelo?
- Â¿CuÃ¡l es la **precisiÃ³n** y **recall** esperados?
- Â¿CuÃ¡ntas detecciones por imagen son **normales**? (1-3? 5-10?)

## ğŸ”§ SOLUCIONES POSIBLES

### OpciÃ³n A: Usar el Modelo .pt Directamente
Si el modelo `.pt` funciona bien en Python, podrÃ­amos:
1. Crear un endpoint API simple en FastAPI/Flask
2. Exponer solo una ruta `/predict` que reciba la imagen
3. Llamar a ese endpoint desde Next.js

**Ventajas**: Usa cÃ³digo que ya funciona
**Desventajas**: Necesita servidor Python corriendo

### OpciÃ³n B: Re-exportar el Modelo Correctamente
Si el problema es la exportaciÃ³n ONNX:
1. Re-exportar con parÃ¡metros especÃ­ficos
2. Verificar que funcione en Python primero (`onnxruntime`)
3. Luego integrarlo en el navegador

### OpciÃ³n C: Usar Ultralytics API
Ultralytics ofrece una API cloud que podrÃ­a servirnos para la demo:
- https://docs.ultralytics.com/hub/

## ğŸ“ PREGUNTAS CLAVE PARA TU AMIGO

1. **Â¿El modelo .onnx funciona correctamente cuando lo pruebas en Python con onnxruntime?**
2. **Â¿Puedes compartir el cÃ³digo de validaciÃ³n/prueba del .onnx?**
3. **Â¿Las coordenadas en la salida estÃ¡n en pÃ­xeles (0-1024) o normalizadas (0-1)?**
4. **Â¿QuÃ© parÃ¡metros de conf/iou usaste al entrenar y validar?**
5. **Â¿Prefieres que usemos el .pt con un servidor Python o arreglamos el .onnx?**

---

**Archivo creado**: 2025-11-27
**Para**: Demo en 4 dÃ­as
**Estado**: Modelo carga correctamente, pero post-procesamiento necesita ajustes
